{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Optimization for Random Forest Regression\n",
    "A random forest regression model is fit and hyperparamters tuned. Several methods are examined by k-fold cross validation performed for each combination of parameter for tuning using GridSearch, RandomizedSearch, Bayesian optimization, and Genetic algorithm. The defualts and ranges for random forest regerssion hyperparameters will be the values we will attempt to optimize. Author: Marc Petta\n",
    "\n",
    "### Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from scipy.stats import uniform, randint\n",
    "from GPyOpt.methods import BayesianOptimization\n",
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "      <td>151.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0  0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1 -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2  0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3 -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4  0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "\n",
       "         s4        s5        s6      Y  \n",
       "0 -0.002592  0.019908 -0.017646  151.0  \n",
       "1 -0.039493 -0.068330 -0.092204   75.0  \n",
       "2 -0.002592  0.002864 -0.025930  141.0  \n",
       "3  0.034309  0.022692 -0.009362  206.0  \n",
       "4 -0.002592 -0.031991 -0.046641  135.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "df = pd.read_csv('diabetes.txt', sep=\",\")\n",
    "# get col names\n",
    "names = list(df.columns.values) \n",
    "# get predictors and assign to object\n",
    "df1 = df.iloc[:,0:9]\n",
    "# assign response to object\n",
    "df2 = df.Y\n",
    "# cast each as numpy array\n",
    "X = pd.DataFrame(df1).to_numpy()\n",
    "y = pd.DataFrame(df2).to_numpy()\n",
    "#Split data into train and test \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Evaluation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to evaluate and return values of r-squared, mean squared error, and plot of model accuracy\n",
    "def my_regression_results(model):\n",
    "    # assess model quality on test data\n",
    "    score_test = model.score(X_test,y_test)\n",
    "    print('Model r-squared score from test data: {:0.4f}'.format(score_test))\n",
    "    # make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    plt.plot(y_test,y_pred,'k.')\n",
    "    plt.xlabel('Test Values')\n",
    "    plt.ylabel('Predicted Values');\n",
    "    # assess accuracy on test-data.\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    mse = mean_squared_error(y_test,y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    print('Mean squared error on test data: {:0.2f}'.format(mse))\n",
    "    print('Root mean squared error on test data: {:0.2f}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline \n",
    "For a baseline model to compare against alternative methods a linear regression will be fit on the training data using defualt values for hyperparameters. Model performance will be assessed on test data and returned from udf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a baseline model object declaring defualt values for hyperparameters\n",
    "model_lr = LinearRegression()\n",
    "# fit the model by calling its fit() method on the training set\n",
    "model_lr.fit(X_train,y_train) # this could be inside the function below too    \n",
    "my_regression_results(model_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randon Forest Regression\n",
    "Fit random forest regression an compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a random forest regression model object declaring defualt values for hyperparameters\n",
    "rf_model = RandomForestRegressor(random_state=0)\n",
    "#Fit model and compare results \n",
    "rf_model.fit(X_train,y_train)\n",
    "my_regression_results(rf_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find no improvement over the linear regression model when applying defualts in Random Forest. Lets see if anything can be done about that.\n",
    "\n",
    "Next, a look at the parameters of a random forest regression to determine if we are able to improve the model performance from above. We will preform k-fold cross validation for each combination of parameter for tuning using several methods. The defualts and ranges for random forest regerssion hyperparameters will be the values we will attempt to optimize.\n",
    "#### GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# define the grid\n",
    "params = {\n",
    "    \"n_estimators\": [50, 100, 135],\n",
    "    \"max_features\": [0.6, 0.8, 1.0],\n",
    "    \"min_samples_split\": [2, 8, 17],\n",
    "    \"min_samples_leaf\": [1, 13, 18],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "# setup the grid search\n",
    "grid_search = GridSearchCV(rf_model,\n",
    "                           param_grid=params,\n",
    "                           cv=5,\n",
    "                           verbose=1,\n",
    "                           n_jobs=1,\n",
    "                           return_train_score=True)\n",
    "# fit the model\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the best parameters found by GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best parameters found by GridSearch\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above provides the best parameters found using GridSearch for optimization. Lets call our results function and see what we get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results for gridsearch\n",
    "my_regression_results(grid_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning hyperparameters with GridSearch shows improvement compared to the defualt random forest defualt model. Lets now proceed with the alternative methods.\n",
    "#### RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter ranges to optimize\n",
    "params = {\n",
    "    \"n_estimators\": randint(10, 150),\n",
    "    \"max_features\": [0.05, 0.1, 0.25, 0.5, 0.75, 1.0],\n",
    "    \"min_samples_split\": randint(2, 20),\n",
    "    \"min_samples_leaf\": randint(1, 20),\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "# setup the random search \n",
    "random_search = RandomizedSearchCV(\n",
    "    rf_model,\n",
    "    param_distributions=params,\n",
    "    random_state=123,\n",
    "    n_iter=25,\n",
    "    cv=5,\n",
    "    verbose=1,\n",
    "    n_jobs=1,\n",
    "    return_train_score=True)\n",
    "# fit model\n",
    "random_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the best parameters found by RandomizedSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get results for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_regression_results(random_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will continue to examine alternative algorithms and provide a final comparative assessment.\n",
    "#### Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num acquisition: 1, time elapsed: 0.79s\n",
      "num acquisition: 2, time elapsed: 1.82s\n",
      "num acquisition: 3, time elapsed: 1.98s\n",
      "num acquisition: 4, time elapsed: 2.18s\n",
      "num acquisition: 5, time elapsed: 2.38s\n",
      "num acquisition: 6, time elapsed: 2.59s\n",
      "num acquisition: 7, time elapsed: 2.78s\n",
      "num acquisition: 8, time elapsed: 3.75s\n",
      "num acquisition: 9, time elapsed: 4.73s\n",
      "num acquisition: 10, time elapsed: 5.72s\n",
      "num acquisition: 11, time elapsed: 6.75s\n",
      "num acquisition: 12, time elapsed: 7.74s\n",
      "num acquisition: 13, time elapsed: 8.82s\n",
      "num acquisition: 14, time elapsed: 9.92s\n",
      "num acquisition: 15, time elapsed: 11.03s\n",
      "num acquisition: 16, time elapsed: 11.95s\n",
      "num acquisition: 17, time elapsed: 12.21s\n",
      "num acquisition: 18, time elapsed: 12.44s\n",
      "num acquisition: 19, time elapsed: 12.64s\n",
      "num acquisition: 20, time elapsed: 12.88s\n"
     ]
    }
   ],
   "source": [
    "# set seed for reproducability\n",
    "np.random.seed(123)\n",
    "\n",
    "# define the parameter ranges to optimize\n",
    "hp_bounds = [{\n",
    "    'name': 'n_estimators',\n",
    "    'type': 'discrete',\n",
    "    'domain': (10, 150)\n",
    "}, {\n",
    "    'name': 'max_features',\n",
    "    'type': 'continuous',\n",
    "    'domain': (0.05, 1.0)\n",
    "}, {\n",
    "    'name': 'min_samples_split',\n",
    "    'type': 'discrete',\n",
    "    'domain': (2, 20)\n",
    "}, {\n",
    "    'name': 'min_samples_leaf',\n",
    "    'type': 'discrete',\n",
    "    'domain': (1, 20)\n",
    "}, {\n",
    "    'name': 'bootstrap',\n",
    "    'type': 'discrete',\n",
    "    'domain': (True, False)\n",
    "}]\n",
    "\n",
    "# optimization objective\n",
    "def cv_score(hyp_parameters):\n",
    "    hyp_parameters = hyp_parameters[0]\n",
    "    rf_model = RandomForestRegressor(random_state=0,\n",
    "                                    n_estimators=int(hyp_parameters[0]),\n",
    "                                    max_features=hyp_parameters[1],\n",
    "                                    min_samples_split=int(hyp_parameters[2]),\n",
    "                                    min_samples_leaf=int(hyp_parameters[3]),\n",
    "                                    bootstrap=bool(hyp_parameters[4]))   \n",
    "    scores = cross_val_score(rf_model,\n",
    "                             X=X_train,\n",
    "                             y=y_train,\n",
    "                             cv=KFold(n_splits=5))\n",
    "    return np.array(scores.mean())  # return average of 5-fold scores\n",
    "\n",
    "\n",
    "optimizer = BayesianOptimization(f=cv_score,\n",
    "                                 domain=hp_bounds,\n",
    "                                 model_type='GP',\n",
    "                                 acquisition_type='EI',\n",
    "                                 acquisition_jitter=0.05,\n",
    "                                 exact_feval=True,\n",
    "                                 maximize=True,\n",
    "                                 verbosity=True)\n",
    "\n",
    "optimizer.run_optimization(max_iter=20,verbosity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at the best parameters found by Bayesion Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 10,\n",
       " 'max_features': 0.5499949703940653,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 20,\n",
       " 'bootstrap': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the coefficients\n",
    "best_hyp_set = {}\n",
    "for i in range(len(hp_bounds)):\n",
    "    if hp_bounds[i]['type'] == 'continuous':\n",
    "        best_hyp_set[hp_bounds[i]['name']] = optimizer.x_opt[i]\n",
    "    else:\n",
    "        best_hyp_set[hp_bounds[i]['name']] = int(optimizer.x_opt[i])\n",
    "best_hyp_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets take those best coefficients and fit the best model and get results for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=0, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features=0.5499949703940653,\n",
       "                      max_leaf_nodes=None, max_samples=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=20, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model with coefficients from the previous Bayesian optimization\n",
    "bayopt_search = RandomForestRegressor(random_state=0,**best_hyp_set)\n",
    "bayopt_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model r-squared score from test data: 0.5155\n",
      "Mean squared error on test data: 3052.38\n",
      "Root mean squared error on test data: 55.25\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#compare results\n",
    "my_regression_results(bayopt_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genetic Algortithm\n",
    "Try some hyperparameter optimization using a Genetic Algorithm from TPOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the parameter ranges to optimize\n",
    "tpot_config = {\n",
    "    'sklearn.ensemble.RandomForestRegressor': {\n",
    "        'n_estimators': [100],\n",
    "        'max_features': np.arange(0.05, 1.01, 0.05),\n",
    "        'min_samples_split': range(2, 21),\n",
    "        'min_samples_leaf': range(1, 21),\n",
    "        'bootstrap': [True, False]\n",
    "    }\n",
    "}\n",
    "# setup the genetic algorithm\n",
    "tpot = TPOTRegressor(generations=5,\n",
    "                     population_size=20,\n",
    "                     verbosity=2,\n",
    "                     config_dict=tpot_config,\n",
    "                     cv=5,\n",
    "                     scoring='r2',\n",
    "                     random_state=123)\n",
    "# fit the model\n",
    "tpot.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get results\n",
    "my_regression_results(tpot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize list of lists \n",
    "data = [['BaseLine', 0.5261, 2985.88, 54.64, '-','-','-','-','-','-' ], ['GridSearch', 0.5575, 2787.80, 54.64 , 810, 50, 0.6, 2, 13, 'T'], ['RandomSearch', 0.5560, 2797.00, 52.89, 125, 74, 0.5, 7, 11, 'T'], ['Bayesian', 0.5155, 3052.38, 55.25, 125, 10, 0.55, 2, 20, 'F'], ['Genetic', 0.5597, 2774.18, 52.67, 600, 100, 0.3500, 8, 10, 'T']] \n",
    "  \n",
    "# Create the pandas DataFrame \n",
    "dfinal = pd.DataFrame(data, columns = ['Name', 'r-squared', 'mean squared error', 'root mean squared error', 'model fits', 'n_estimators','max_features', 'min_samples_split', 'min_samples_leaf', 'bootstrap']) \n",
    "  \n",
    "# print dataframe. \n",
    "dfinal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What purpose this model is used for would ultimately determine which would be considered best. In terms of r-squared the table above illustrates Bayesian Optimization having performed better than the baseline random forest with defualt hyperparameters. If decreasing error in the model is paramount then we find that all alternative methods except Bayesian display lower values of mean squared error. As this is simply an illustration of procedure depending on application of the model the process above can help determine optimized hyperparameters. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
